# ğŸ—ï¸ Current Affairs Hub

**Current Affairs Hub** is a full-stack Python project designed to help you **learn web scraping, data processing, storage, categorization, and frontend visualization** using real-world current affairs from trusted news sources. It scrapes news articles via RSS feeds, categorizes them using rule-based logic, stores them in an SQLite database, and displays them in a clean dashboard using Streamlit.

> âš¡ This project was built with learning as the top priority â€” each phase is structured to gradually teach concepts and build hands-on skills.

---

## ğŸ” Table of Contents

- [Features](#features)
- [How It Works (Explained)](#how-it-works-explained)
- [Project Structure](#project-structure)
- [Setup Instructions](#setup-instructions)
- [How to Use](#how-to-use)
- [Tech Stack](#tech-stack)
- [License](#license)

---

## âœ… Features

- ğŸ” Scrapes articles from RSS feeds (TechCrunch, IGN, ScienceDaily, BBC, etc.)
- ğŸ§  Classifies articles into categories like Tech, Science, Politics, Gaming, etc.
- ğŸ§¾ Stores data in a SQLite database with no duplicates
- ğŸ–¥ï¸ Streamlit dashboard with filter tabs and refresh functionality
- ğŸ§° Easy to extend and modular design
- ğŸ§ª Built step-by-step to improve learning and debugging

---

## ğŸ§  How It Works (Explained)

This section explains **what each module does** and **why we need it**:

### 1. `rss_scraper.py` â€” **Scraping News via RSS**

- Uses `feedparser` to fetch articles from RSS feed URLs.
- Each feed provides a list of articles (`title`, `summary`, `link`, `published`, etc.).
- Outputs a list of articles in a standard Python dict format.

ğŸ“š **Concepts Learned**: RSS parsing, feed structures, basic Python dictionaries.

---

### 2. `categorizer.py` â€” **Classifying Articles**

- Uses simple **keyword-based logic** to assign a category (e.g., "AI", "Politics", "Science") based on words found in the title and summary.
- If nothing matches, defaults to `"Uncategorized"`.

ğŸ“š **Concepts Learned**: Rule-based classification, working with strings and lists, improving logic.

---

### 3. `news.py` â€” **Creating the Database Model**

- Defines a `News` class using SQLAlchemy.
- Maps Python objects to rows in a SQLite table called `news`.

ğŸ“š **Concepts Learned**: Object Relational Mapping (ORM), working with databases in Python.

---

### 4. `news_ops.py` â€” **Inserting & Deduplication**

- Checks for duplicate `url` before inserting to avoid repeated articles.
- Handles inserting articles with timestamp and category.

ğŸ“š **Concepts Learned**: Deduplication, database sessions, and clean data handling.

---

### 5. `fetch_and_store.py` â€” **Orchestrator Script**

- Fetches feeds â†’ categorizes â†’ inserts into database.
- You can run it manually or trigger it via Streamlit refresh button.

ğŸ“š **Concepts Learned**: Integration logic, modular functions, automation.

---

### 6. `main.py` (Streamlit) â€” **Dashboard**

- Displays articles using `st.write()` and markdown links.
- Has category filters and a "Refresh" button to re-fetch live data.

ğŸ“š **Concepts Learned**: Frontend thinking, Streamlit components, dynamic filtering.

---

## ğŸ“ Project Structure

```

currentAffairsHub/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ categorizer/            # Keyword-based logic
â”‚   â”œâ”€â”€ db/                     # Insert logic with deduplication
â”‚   â”œâ”€â”€ models/                 # SQLAlchemy ORM for news
â”‚   â””â”€â”€ scraping/               # Feed sources and scraping logic
â”œâ”€â”€ data/                       # news.db lives here
â”œâ”€â”€ scripts/                    # CLI scripts for setup/fetch
â”œâ”€â”€ streamlit\_app/              # Dashboard UI
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

```

---

## ğŸ› ï¸ Setup Instructions

1. **Clone the repository**

```bash
git clone https://github.com/your-username/currentAffairsHub.git
cd currentAffairsHub
```

2. **Create a virtual environment**

```bash
python3 -m venv .venv
source .venv/bin/activate
```

3. **Install dependencies**

```bash
python3 -m pip install --upgrade pip
python3 -m pip install -r requirements.txt
```

4. **Initialize the database**

```bash
python3 -m scripts.init_db
```

5. **Fetch and store articles**

```bash
python3 -m scripts.fetch_and_store
```

6. **Run the dashboard**

```bash
streamlit run streamlit_app/main.py
```

---

## ğŸ“¦ Tech Stack

| Tool          | Purpose                        |
| ------------- | ------------------------------ |
| Python        | Core language                  |
| feedparser    | RSS feed parsing               |
| SQLAlchemy    | Database ORM                   |
| SQLite        | Lightweight storage            |
| Streamlit     | Frontend dashboard             |
| BeautifulSoup | (Reserved for future scraping) |

---

## ğŸ“… Phased Learning Progress

| Phase | Description          | Status             |
| ----- | -------------------- | ------------------ |
| 1     | Planning & Setup     | âœ… Done            |
| 2     | RSS Feed Scraping    | âœ… Done            |
| 3     | Categorization Logic | âœ… Done            |
| 4     | Data Storage         | âœ… Done            |
| 5     | Streamlit Dashboard  | âœ… Done            |
| 6     | Dockerization        | â³ Skipped for now |

---

## ğŸ™Œ Credits

- Built by **Kanchan**, guided by ChatGPT
- Inspired by the need to learn _how real web applications are built_
